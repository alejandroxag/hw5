{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw5ersgan.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NiEXGRliytD"
      },
      "source": [
        "# set up\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tD8ut16vdTmA",
        "outputId": "d36b5be7-f963-4a9f-e072-5282ef05d399"
      },
      "source": [
        "#connect to gdrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "%cd gdrive/MyDrive\n",
        "#%cd ../..\n",
        "!pwd\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "/content/gdrive/MyDrive\n",
            "/content/gdrive/MyDrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BjYVPnOdkPn",
        "outputId": "45c4d7ec-38a8-4428-81ec-2032482260d6"
      },
      "source": [
        "import torch\n",
        "%cd competitions/hw5\n",
        "cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if cuda else \"cpu\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive/competitions/hw5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cXhuhLgjO8D"
      },
      "source": [
        "# preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wm5WLUyieRR4"
      },
      "source": [
        "from PIL import Image\n",
        "import PIL.ImageOps  \n",
        "from torchvision import transforms\n",
        "import numpy as np\n",
        "from os import listdir\n",
        "import torchvision\n",
        "import torch\n",
        "def is_image(filename):\n",
        "  return any(filename.endswith(extension) for extension in ['png'])\n",
        "\n",
        "\n",
        "class TrainDataset(object):\n",
        "    def __init__(self,lrimagefolder,hrimagefolder,transform=None,should_invert=False, test = False):\n",
        "        super(TrainDataset,self).__init__()\n",
        "        \n",
        "        self.hrimagefolder = hrimagefolder\n",
        "        self.lrimagefolder = lrimagefolder  \n",
        "        if transform:\n",
        "          self.transformhr = transform[0]\n",
        "          self.transformlr = transform[1]\n",
        "        else:\n",
        "          self.transformhr = None\n",
        "          self.transformlr = None\n",
        "        self.should_invert = should_invert\n",
        "        self.hrdir = sorted(listdir(hrimagefolder))\n",
        "        self.lrdir = sorted(listdir(lrimagefolder))\n",
        "\n",
        "\n",
        "        #self.hr_transform = train_hr_transform(crop_size)\n",
        "        #self.lr_transform = train_lr_transform(crop_size, upscale_factor)\n",
        "        self.test = test\n",
        "\n",
        "\n",
        "    def __getitem__(self,index):\n",
        "\n",
        "        dirnamehr =  self.hrimagefolder + '/' + self.hrdir[index]\n",
        "        dirnamelr =  self.lrimagefolder + '/' + self.lrdir[index]\n",
        "\n",
        "\n",
        "        imghr = Image.open(dirnamehr)\n",
        "        imglr = Image.open(dirnamelr)\n",
        "        \n",
        "\n",
        "        if self.transformhr is not None:\n",
        "\n",
        "          imghr = self.transformhr(imghr)\n",
        "          imglr = self.transformlr(imglr)\n",
        "        imghr = transforms.ToTensor()(imghr)\n",
        "        imglr = transforms.ToTensor()(imglr)\n",
        "\n",
        "      \n",
        "        if self.test == False:\n",
        "          return imghr, imglr\n",
        "        \"\"\"\n",
        "        else:\n",
        "          return img0, img1 ,0\n",
        "        \"\"\"\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.hrdir)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEJG_Ep3oVpn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "98dae1e8-e9fe-49d0-fa5c-656e58f3a5ac"
      },
      "source": [
        "\"\"\"this will be loaded later while training\n",
        "t = [torchvision.transforms.Compose([transforms.CenterCrop(600),]),torchvision.transforms.Compose([transforms.CenterCrop(150),])]\n",
        "lrimagefolder = 'DIV2K_train_LR_bicubic/X4'\n",
        "hrimagefolder = 'DIV2K_train_HR'\n",
        "train_dataset = TrainDataset(lrimagefolder, hrimagefolder, transform=t)\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, shuffle = True, num_workers = 0, batch_size = 4)\n",
        "\"\"\""
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"this will be loaded later while training\\nt = [torchvision.transforms.Compose([transforms.CenterCrop(600),]),torchvision.transforms.Compose([transforms.CenterCrop(150),])]\\nlrimagefolder = 'DIV2K_train_LR_bicubic/X4'\\nhrimagefolder = 'DIV2K_train_HR'\\ntrain_dataset = TrainDataset(lrimagefolder, hrimagefolder, transform=t)\\ntrain_dataloader = torch.utils.data.DataLoader(train_dataset, shuffle = True, num_workers = 0, batch_size = 4)\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWy6VnOlFzDP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "f777bbca-fe79-48be-afc3-49842a32a158"
      },
      "source": [
        "\"\"\"\n",
        "t = [torchvision.transforms.Compose([transforms.CenterCrop(400),]),torchvision.transforms.Compose([transforms.CenterCrop(100),])]\n",
        "lrimagefolder = 'DIV2K_valid_LR_bicubic/X4'\n",
        "hrimagefolder = 'DIV2K_valid_HR'\n",
        "valid_dataset = TrainDataset(lrimagefolder, hrimagefolder, transform=t)\n",
        "valid_dataloader = torch.utils.data.DataLoader(valid_dataset, shuffle = False, num_workers = 0, batch_size = 1)\n",
        "\"\"\""
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nt = [torchvision.transforms.Compose([transforms.CenterCrop(400),]),torchvision.transforms.Compose([transforms.CenterCrop(100),])]\\nlrimagefolder = 'DIV2K_valid_LR_bicubic/X4'\\nhrimagefolder = 'DIV2K_valid_HR'\\nvalid_dataset = TrainDataset(lrimagefolder, hrimagefolder, transform=t)\\nvalid_dataloader = torch.utils.data.DataLoader(valid_dataset, shuffle = False, num_workers = 0, batch_size = 1)\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "cn86vGIeqjql",
        "outputId": "f732f7e9-433c-4819-f4a7-85aa70dc1c29"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\"\"\"\n",
        "for a, b in train_dataloader:\n",
        "  print(a.shape, b.shape)\n",
        "\n",
        "  plt.imshow( b[0].permute(1, 2, 0)  )\n",
        "  del a\n",
        "  del b\n",
        "  break\n",
        "\"\"\""
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nfor a, b in train_dataloader:\\n  print(a.shape, b.shape)\\n\\n  plt.imshow( b[0].permute(1, 2, 0)  )\\n  del a\\n  del b\\n  break\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNY7fw4pjd23"
      },
      "source": [
        "# model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhdPtB62jeYy"
      },
      "source": [
        "from torch import nn\n",
        "\n",
        "class ResidualDenseBlock(nn.Module):\n",
        "    def __init__(self, channels = 64, growth_channels = 32, scale_ratio = 0.2):\n",
        "\n",
        "        super(ResidualDenseBlock, self).__init__()\n",
        "        convlayer = []\n",
        "        for i in range(5):\n",
        "          if i != 4:\n",
        "            convlayer.append(nn.Conv2d(channels + i* growth_channels, growth_channels, kernel_size=3, stride=1, padding=1))\n",
        "          else:\n",
        "            convlayer.append(nn.Conv2d(channels + i* growth_channels, channels, kernel_size=3, stride=1, padding=1))\n",
        "        self.convlayer = nn.Sequential(*convlayer)\n",
        "        self.scale_ratio = scale_ratio\n",
        "        self.relu = nn.LeakyReLU(negative_slope = 0.2, inplace = True)\n",
        "\n",
        "\n",
        "    def forward(self, x) :\n",
        "\n",
        "        origin_x = x\n",
        "        catlayer = []\n",
        "        for num,l in enumerate(self.convlayer):\n",
        "          \n",
        "          if num == 0:\n",
        "            catlayer.append(x)\n",
        "            x = self.relu(l(x))\n",
        "          elif num> 0 and num< 4 :\n",
        "            \n",
        "            catlayer.append(x)\n",
        "            \n",
        "            input = torch.cat(catlayer,1)\n",
        "            x = self.relu(l(input))\n",
        "          else:\n",
        "            catlayer.append(x)\n",
        "            input = torch.cat(catlayer,1)\n",
        "            x = l(input)\n",
        "\n",
        "        return x * self.scale_ratio + origin_x"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHLCtf0zFdeA"
      },
      "source": [
        "class RRDB(nn.Module):\n",
        "\n",
        "    def __init__(self, channels = 64, growth_channels=32,scale_ratio = 0.2):\n",
        "        super(RRDB, self).__init__()\n",
        "        self.RDB1 = ResidualDenseBlock(channels, growth_channels,scale_ratio )\n",
        "        self.RDB2 = ResidualDenseBlock(channels, growth_channels,scale_ratio)\n",
        "        self.RDB3 = ResidualDenseBlock(channels, growth_channels,scale_ratio)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.RDB1(x)\n",
        "        out = self.RDB2(out)\n",
        "        out = self.RDB3(out)\n",
        "        return out * 0.2 + x"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5zeDn8PkPDZ"
      },
      "source": [
        "class upsampleblock(torch.nn.Module):\n",
        "  def __init__(self, in_channel, scale = 2):\n",
        "    super(upsampleblock, self).__init__()\n",
        "    self.conv = nn.Conv2d(in_channel, in_channel *scale * 2, kernel_size = 3, stride = 1, padding = 1)\n",
        "    self.pixel_shuffle = nn.PixelShuffle(upscale_factor = scale)\n",
        "    self.prelu = nn.PReLU()\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x = self.conv(x)\n",
        "    x = self.pixel_shuffle(x)\n",
        "    x = self.prelu(x)\n",
        "    return x"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdaHq9fSFf_v"
      },
      "source": [
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, num_rrdb= 16):\n",
        "        super(Generator, self).__init__()\n",
        "        #p1\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)\n",
        "        rrdblayers = []\n",
        "        for _ in range(num_rrdb):\n",
        "            rrdblayers.append(RRDB(channels=64, growth_channels=32, scale_ratio=0.2))\n",
        "\n",
        "        self.rrdb= nn.Sequential(*rrdblayers)\n",
        "\n",
        "        # p2\n",
        "        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "        # p3 with upsample\n",
        "        upsample_num = 2\n",
        "        upblock = []\n",
        "        for _ in range(upsample_num):\n",
        "          upblock.append(upsampleblock(64))\n",
        "          \n",
        "        self.upblock = nn.Sequential(*upblock)\n",
        "\n",
        "        # p3 conv\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.LeakyReLU(negative_slope=0.2, inplace=True)\n",
        "        )\n",
        "\n",
        "        # Final output layer\n",
        "        self.conv4 = nn.Conv2d(64, 3, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        out = self.conv1(x)\n",
        "        rrdblyr = self.rrdb(out)\n",
        "        out2 = self.conv2(rrdblyr)\n",
        "        out = torch.add(out, out2)\n",
        "        out = self.upblock(out)\n",
        "        out = self.conv3(out)\n",
        "        out = self.conv4(out)\n",
        "\n",
        "        return out"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ao_3Z6J_mRD1"
      },
      "source": [
        "\n",
        "class Discriminator(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    block_channel = [64, 128, 256, 512]#original: 64, 128, 256, 512\n",
        "\n",
        "    longblock = []\n",
        "    inchannel = 3\n",
        "    out = 64\n",
        "    for b in range(len(block_channel)):\n",
        "      out = block_channel[b]\n",
        "      if b == 0:\n",
        "        longblock.append(nn.Conv2d(inchannel,out, kernel_size = 3, stride = 1, padding = 1))\n",
        "        longblock.append(nn.LeakyReLU(0.2))\n",
        "      else:\n",
        "        longblock.append(nn.Conv2d(inchannel,out, kernel_size = 3, stride = 1, padding = 1))\n",
        "        longblock.append(nn.BatchNorm2d(out))\n",
        "        longblock.append(nn.LeakyReLU(0.2))\n",
        "      inchannel = out\n",
        "      longblock.append(nn.Conv2d(inchannel,out, kernel_size = 3, stride = 2, padding = 1))\n",
        "      longblock.append(nn.BatchNorm2d(out))\n",
        "      longblock.append(nn.LeakyReLU(0.2))\n",
        "    \n",
        "    self.longblock = nn.Sequential(*longblock)\n",
        "    \n",
        "    self.classifier = nn.Sequential(\n",
        "        nn.AdaptiveAvgPool2d(1),\n",
        "        nn.Conv2d(512, 1024, kernel_size=1),# original 512 1024\n",
        "        nn.LeakyReLU(0.2),\n",
        "        nn.Conv2d(1024,1, kernel_size = 1) #original 1024\n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "\n",
        "    x = self.longblock(x)\n",
        "    x = self.classifier(x)\n",
        "    x = x.flatten(start_dim = 1)\n",
        "    return torch.sigmoid(x)\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TpQh1VUYO9q"
      },
      "source": [
        "#training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIi6t5E2YHKM"
      },
      "source": [
        "from torch import nn\n",
        "from torchvision.models.vgg import vgg19\n",
        "\n",
        "\n",
        "class GeneratorLoss(nn.Module):\n",
        "    def __init__(self, before_act = True):\n",
        "        super(GeneratorLoss, self).__init__()\n",
        "        vgg = vgg19(pretrained=True)\n",
        "        vggloss= nn.Sequential(*list(vgg.features)[:11]).eval()  #6, \n",
        "\n",
        "        for param in vggloss.parameters():\n",
        "            param.requires_grad = False\n",
        "        self.vggloss = vggloss.to(device)\n",
        "\n",
        "        self.mse_loss = nn.MSELoss().to(device)\n",
        "\n",
        "    def forward(self, out_labels, out_images, target_images):\n",
        "        # Adversarial Loss\n",
        "        adversarial_loss = torch.mean(1 - out_labels)\n",
        "        # Perception Loss\n",
        "        vgg_loss = self.mse_loss(self.vggloss(out_images), self.vggloss(target_images))\n",
        "        # Image Loss\n",
        "        image_loss = self.mse_loss(out_images, target_images)\n",
        "\n",
        "        return image_loss + 0.001*adversarial_loss + 0.006*vgg_loss"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gf9eaCyT-IXg"
      },
      "source": [
        "\n",
        "def training(epoch, G_optimizer, D_optimizer, lr,netG, netD, train_dataloader = None):\n",
        "  gloss = 0\n",
        "  dloss = 0\n",
        "  dscore = 0\n",
        "  gscore = 0\n",
        "\n",
        "  netG.train()\n",
        "  netD.train()\n",
        "  t = [torchvision.transforms.Compose([transforms.CenterCrop(400),]),torchvision.transforms.Compose([transforms.CenterCrop(100),])]\n",
        "  lrimagefolder = 'DIV2K_train_LR_bicubic/X4'\n",
        "  hrimagefolder = 'DIV2K_train_HR'\n",
        "  train_dataset = TrainDataset(lrimagefolder, hrimagefolder, transform=t)\n",
        "  train_dataloader = torch.utils.data.DataLoader(train_dataset, shuffle = True, num_workers = 0, batch_size = 4)\n",
        "  \n",
        "  for imagehr, imagelr in train_dataloader:\n",
        "\n",
        "    ##########################################discriminator##############################################\n",
        "    imagehr = Variable(imagehr).to(device)\n",
        "    imagelr = Variable(imagelr).to(device)   \n",
        "   \n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    D_optimizer.zero_grad()\n",
        "\n",
        "    real_label = torch.full(size=(len(imagehr),), fill_value=0.99, dtype=torch.float, device=device)\n",
        "    realout = netD(imagehr).view(-1)\n",
        "\n",
        "    err_D_real = dcriterion(realout, real_label)\n",
        "    err_D_real.backward()\n",
        "\n",
        "    fake_label = torch.full(size=(len(imagehr),), fill_value=0, dtype=torch.float, device=device)\n",
        "    fakeimg = netG(imagelr)\n",
        "    \n",
        "    fakeout = netD(fakeimg.detach()).view(-1)\n",
        "    err_D_fake = dcriterion(fakeout, fake_label)\n",
        "    err_D_fake.backward()\n",
        "\n",
        "    D_optimizer.step()\n",
        "    \n",
        "    dloss += err_D_fake.item() + err_D_real.item()\n",
        "    \n",
        "    \n",
        "    del realout\n",
        "    del real_label\n",
        "    del err_D_real\n",
        "    del fakeout\n",
        "    \n",
        "    #############################################generator#####################################################\n",
        "  \n",
        "    torch.cuda.empty_cache()\n",
        "    G_optimizer.zero_grad()\n",
        "    # criterion\n",
        "    fakeout = netD(fakeimg)\n",
        "    g_loss = gcriterion(fakeout, fakeimg, imagehr)\n",
        "\n",
        "    gloss += g_loss.item()\n",
        "\n",
        "    g_loss.backward(retain_graph=True)\n",
        "    G_optimizer.step()\n",
        "\n",
        "    del imagehr\n",
        "    del imagelr\n",
        "    del fakeout\n",
        "    del fakeimg\n",
        "    del g_loss\n",
        "    \n",
        "  scheduler.step(dloss)\n",
        "  print('epoch',epoch,'gloss: ', gloss, ' dloss:', dloss)\n",
        "  del train_dataloader\n",
        "  torch.cuda.empty_cache()\n",
        "\n",
        "from math import log10\n",
        "def val(netG, netD, valid_dataloader=None):\n",
        "  netG.eval()\n",
        "  netD.eval()\n",
        "\n",
        "  psnr_total = []\n",
        "  ssim_total = []\n",
        "  lrimagefolder = 'DIV2K_valid_LR_bicubic/X4'\n",
        "  hrimagefolder = 'DIV2K_valid_HR'\n",
        "  valid_dataset = TrainDataset(lrimagefolder, hrimagefolder, transform=None)\n",
        "  valid_dataloader = torch.utils.data.DataLoader(valid_dataset, shuffle = False, num_workers = 0, batch_size = 1)\n",
        "  with torch.no_grad():\n",
        "    for imagehr, imagelr in valid_dataloader:\n",
        "\n",
        "      imagehr = Variable(imagehr).to(device)\n",
        "      imagelr = Variable(imagelr).to(device)   \n",
        "      fakeimg = netG(imagelr)\n",
        "\n",
        "      s = ssim(imagehr, fakeimg)\n",
        "      ssim_total.append(s.item())\n",
        "\n",
        "      p =  ((imagehr - fakeimg) ** 2).data.mean()\n",
        "      psnr = 10 * log10(1 / p)\n",
        "      psnr_total.append(psnr)\n",
        "\n",
        "      del imagehr\n",
        "      del imagelr\n",
        "      del fakeimg\n",
        "      torch.cuda.empty_cache()\n",
        "\n",
        "    print('psnr: ',np.mean(psnr_total), 'ssim: ',np.mean(ssim_total))\n",
        "    \n",
        "    if np.mean(psnr_total) > 25.6 and np.mean(ssim_total)>0.718:\n",
        "      print('saving model')\n",
        "      torch.save(netG,'netg_ersgan72')\n",
        "      torch.save(netD,'netd_ersgan072')\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1knysPUBXfv2"
      },
      "source": [
        "# Tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0kBOkMyYy95"
      },
      "source": [
        "from math import exp\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "\n",
        "#evaluation\n",
        "def calculate_psnr(imgfake, imgreal):\n",
        "  imgfake = imgfake.astype(np.float64)\n",
        "  imgreal = imgreal.astype(np.float64)\n",
        "  mse = np.mean((imgreal - imgfake)**2)\n",
        "  return 20* math.log10(255 /math.sqrt(mse))\n",
        "\n",
        "def gaussian(window_size, sigma):\n",
        "    gauss = torch.Tensor([exp(-(x - window_size // 2) ** 2 / float(2 * sigma ** 2)) for x in range(window_size)])\n",
        "    return gauss / gauss.sum()\n",
        "\n",
        "\n",
        "def create_window(window_size, channel):\n",
        "    _1D_window = gaussian(window_size, 1.5).unsqueeze(1)\n",
        "    _2D_window = _1D_window.mm(_1D_window.t()).float().unsqueeze(0).unsqueeze(0)\n",
        "    window = Variable(_2D_window.expand(channel, 1, window_size, window_size).contiguous())\n",
        "    return window\n",
        "\n",
        "\n",
        "def _ssim(img1, img2, window, window_size, channel, size_average=True):\n",
        "    mu1 = F.conv2d(img1, window, padding=window_size // 2, groups=channel)\n",
        "    mu2 = F.conv2d(img2, window, padding=window_size // 2, groups=channel)\n",
        "\n",
        "    mu1_sq = mu1.pow(2)\n",
        "    mu2_sq = mu2.pow(2)\n",
        "    mu1_mu2 = mu1 * mu2\n",
        "\n",
        "    sigma1_sq = F.conv2d(img1 * img1, window, padding=window_size // 2, groups=channel) - mu1_sq\n",
        "    sigma2_sq = F.conv2d(img2 * img2, window, padding=window_size // 2, groups=channel) - mu2_sq\n",
        "    sigma12 = F.conv2d(img1 * img2, window, padding=window_size // 2, groups=channel) - mu1_mu2\n",
        "\n",
        "    C1 = 0.01 ** 2\n",
        "    C2 = 0.03 ** 2\n",
        "\n",
        "    ssim_map = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2)) / ((mu1_sq + mu2_sq + C1) * (sigma1_sq + sigma2_sq + C2))\n",
        "\n",
        "    if size_average:\n",
        "        return ssim_map.mean()\n",
        "    else:\n",
        "        return ssim_map.mean(1).mean(1).mean(1)\n",
        "\n",
        "\n",
        "class SSIM(torch.nn.Module):\n",
        "    def __init__(self, window_size=11, size_average=True):\n",
        "        super(SSIM, self).__init__()\n",
        "        self.window_size = window_size\n",
        "        self.size_average = size_average\n",
        "        self.channel = 1\n",
        "        self.window = create_window(window_size, self.channel)\n",
        "\n",
        "    def forward(self, img1, img2):\n",
        "        (_, channel, _, _) = img1.size()\n",
        "\n",
        "        if channel == self.channel and self.window.data.type() == img1.data.type():\n",
        "            window = self.window\n",
        "        else:\n",
        "            window = create_window(self.window_size, channel)\n",
        "\n",
        "            if img1.is_cuda:\n",
        "                window = window.cuda(img1.get_device())\n",
        "            window = window.type_as(img1)\n",
        "\n",
        "            self.window = window\n",
        "            self.channel = channel\n",
        "\n",
        "        return _ssim(img1, img2, window, self.window_size, channel, self.size_average)\n",
        "\n",
        "\n",
        "def ssim(img1, img2, window_size=11, size_average=True):\n",
        "    (_, channel, _, _) = img1.size()\n",
        "    window = create_window(window_size, channel)\n",
        "\n",
        "    if img1.is_cuda:\n",
        "        window = window.cuda(img1.get_device())\n",
        "    window = window.type_as(img1)\n",
        "\n",
        "    return _ssim(img1, img2, window, window_size, channel, size_average)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09aOpoyN-yKe"
      },
      "source": [
        "from torch.autograd import Variable\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "netG = Generator()\n",
        "netD = Discriminator()\n",
        "netG.to(device)\n",
        "netD.to(device)\n",
        "\n",
        "lr = 0.0002\n",
        "epochs = 20\n",
        "\n",
        "gcriterion = GeneratorLoss()\n",
        "dcriterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "G_optimizer = optim.Adam(netG.parameters(), lr = lr, betas = (0.5, 0.9))\n",
        "D_optimizer = optim.Adam(netD.parameters(), lr = lr, betas = (0.5, 0.9))\n",
        "scheduler =torch.optim.lr_scheduler.ReduceLROnPlateau(D_optimizer, 'min', 0.75,2)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  training(epoch, G_optimizer, D_optimizer, lr,netG, netD)\n",
        "  val(netG, netD)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVYiD8oF5_VI"
      },
      "source": [
        "# Test"
      ]
    }
  ]
}