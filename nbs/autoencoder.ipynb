{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30871,
     "status": "ok",
     "timestamp": 1619651062046,
     "user": {
      "displayName": "Alejandro Alvarez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiJwO-DJto5fe7l3jpfrxCyKXIyVCJ_fxyVkAhw5g=s64",
      "userId": "03843718286559301780"
     },
     "user_tz": 240
    },
    "id": "sQ20qAxkQu8s",
    "outputId": "5af1568e-ea40-49eb-ee90-f15f7e51f60e"
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# os.chdir('./drive/MyDrive/CMU/spring_2021/IDL/hw/hw5/nbs')\n",
    "# print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "BPe60tNhQu9E"
   },
   "outputs": [],
   "source": [
    "#default_exp autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ByOxee8lQu9F"
   },
   "source": [
    "# Autoencoder for Image Super-Resolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kOkdovdHQu9G"
   },
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1303,
     "status": "ok",
     "timestamp": 1619651065543,
     "user": {
      "displayName": "Alejandro Alvarez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiJwO-DJto5fe7l3jpfrxCyKXIyVCJ_fxyVkAhw5g=s64",
      "userId": "03843718286559301780"
     },
     "user_tz": 240
    },
    "id": "oWykTuXDQu9H",
    "outputId": "084bf1f0-8e0e-4d93-a24e-7f5d8fda9bc2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/hw5\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('..')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 0, 0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#export\n",
    "import gc\n",
    "gc.collect()\n",
    "gc.get_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8705,
     "status": "ok",
     "timestamp": 1619651075951,
     "user": {
      "displayName": "Alejandro Alvarez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiJwO-DJto5fe7l3jpfrxCyKXIyVCJ_fxyVkAhw5g=s64",
      "userId": "03843718286559301780"
     },
     "user_tz": 240
    },
    "id": "_I-VU90gQu9H",
    "outputId": "50ef5eeb-e69a-4c71-db33-09cf3ba8813c"
   },
   "outputs": [],
   "source": [
    "# !pip install torchinfo\n",
    "# !pip install pytorch-ignite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 796,
     "status": "ok",
     "timestamp": 1619652612849,
     "user": {
      "displayName": "Alejandro Alvarez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiJwO-DJto5fe7l3jpfrxCyKXIyVCJ_fxyVkAhw5g=s64",
      "userId": "03843718286559301780"
     },
     "user_tz": 240
    },
    "id": "_Wy3Q4D5Qu9I"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "# imports\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pytorch_ssim\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from torchinfo import summary\n",
    "from ignite.metrics import PSNR, SSIM\n",
    "from torchvision import transforms\n",
    "from torch.optim import AdamW, lr_scheduler\n",
    "import torchvision.transforms.functional as TF\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q5sog-8gQu9I"
   },
   "source": [
    "## Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 625,
     "status": "ok",
     "timestamp": 1619652618768,
     "user": {
      "displayName": "Alejandro Alvarez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiJwO-DJto5fe7l3jpfrxCyKXIyVCJ_fxyVkAhw5g=s64",
      "userId": "03843718286559301780"
     },
     "user_tz": 240
    },
    "id": "isL6L22RQu9J"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "class PicturesDataset(Dataset):\n",
    "\n",
    "    def __init__(self,\n",
    "                 mode,\n",
    "                 final_size,\n",
    "                 normalize=False,\n",
    "                 data_augmentation=None,\n",
    "                 interpolation=TF.InterpolationMode.NEAREST,\n",
    "                 in_memory=False,\n",
    "                 verbose=False):\n",
    "\n",
    "        s = time.time()\n",
    "\n",
    "        # Assertions to avoid wrong inputs\n",
    "        assert mode in ['train', 'val', 'test']\n",
    "        assert (mode != 'train' and data_augmentation == None) or mode == 'train'\n",
    "        if data_augmentation != None:\n",
    "            for item in data_augmentation:\n",
    "                assert item in ['crop', 'rotate', 'flip']\n",
    "\n",
    "        # Directory setup\n",
    "        data_dirs = {'train': './data/train',\n",
    "                     'val': './data/val',\n",
    "                     'test': './data/test'}\n",
    "\n",
    "        self.data_dir = data_dirs[mode]\n",
    "        self.mode = mode\n",
    "        self.final_size = final_size\n",
    "        self.data_augmentation = data_augmentation\n",
    "        self.normalize = normalize\n",
    "        self.verbose = verbose\n",
    "        self.interpolation = interpolation\n",
    "        self.in_memory=in_memory\n",
    "\n",
    "        self.final_size_transf = transforms.Resize(size=[self.final_size, self.final_size],\n",
    "                                                   interpolation=self.interpolation)\n",
    "        \n",
    "        self.pic_to_tensor = transforms.ToTensor()\n",
    "\n",
    "        if mode != 'test':\n",
    "            self.file_names_lr = sorted(glob.glob(f'{self.data_dir}/lr/*.png'))\n",
    "            self.file_names_hr = sorted(glob.glob(f'{self.data_dir}/hr/*.png'))\n",
    "            \n",
    "            if in_memory:\n",
    "                self.pics_lr = [self.pic_to_tensor(Image.open(f)) for f in self.file_names_lr]\n",
    "                self.pics_hr = [self.pic_to_tensor(Image.open(f)) for f in self.file_names_hr]\n",
    "                    \n",
    "        else:\n",
    "            self.file_names_lr = []\n",
    "            for dir in os.listdir(self.data_dir):\n",
    "                self.file_names_lr += glob.glob(f'{self.data_dir}/{dir}/*.png')\n",
    "            self.file_names_lr = sorted(self.file_names_lr)\n",
    "            \n",
    "            if in_memory:\n",
    "                self.pics_lr = [self.pic_to_tensor(Image.open(f)) for f in self.file_names_lr]\n",
    "\n",
    "        if verbose: print(f'class PicturesDataset Init time: {time.time() - s:0.2f}')\n",
    "   \n",
    "\n",
    "    def __len__(self): \n",
    "        return len(self.file_names_lr)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "            \n",
    "        # Low resolution image (x)\n",
    "        s = time.time()\n",
    "        if self.in_memory: pic_lr = self.pics_lr[idx]     \n",
    "        else: pic_lr = transforms.ToTensor()(Image.open(self.file_names_lr[idx]))      \n",
    "        if self.verbose: print(f'LR image reading time: {time.time() - s:0.2f}')\n",
    "\n",
    "        # Flip dimensions to have height as longest dimension\n",
    "        s = time.time()\n",
    "        if pic_lr.shape[2] > pic_lr.shape[1]:\n",
    "            pic_lr = pic_lr.transpose(1, 2)\n",
    "        if self.verbose: print(f'LR Flipping time: {time.time() - s:0.2f}')\n",
    "\n",
    "        # Normalization\n",
    "        s = time.time()\n",
    "        if self.normalize:\n",
    "            pic_lr_mean = torch.mean(pic_lr.flatten(start_dim=1), dim=1)\n",
    "            pic_lr_std = torch.std(pic_lr.flatten(start_dim=1), dim=1)\n",
    "            pic_lr = TF.normalize(pic_lr, mean=pic_lr_mean, std=pic_lr_std)\n",
    "        if self.verbose: print(f'LR Normalization time: {time.time() - s:0.2f}')\n",
    "\n",
    "        # 4x rescaling\n",
    "        s = time.time()\n",
    "        pic_lr_h, pic_lr_w = pic_lr.shape[1], pic_lr.shape[2]\n",
    "        pic_lr = TF.resize(pic_lr,\n",
    "                           size=[4*pic_lr_h, 4*pic_lr_w],\n",
    "                           interpolation=self.interpolation)\n",
    "        if self.verbose: print(f'LR Rescaling time: {time.time() - s:0.2f}')        \n",
    "        \n",
    "        if self.mode != 'test':\n",
    "\n",
    "            # High resolution image (target, just for training and validation)\n",
    "            s = time.time()\n",
    "            if self.in_memory: pic_hr = self.pics_hr[idx]     \n",
    "            else: pic_hr = transforms.ToTensor()(Image.open(self.file_names_hr[idx])) \n",
    "            if self.verbose: print(f'HR image reading time: {time.time() - s:0.2f}')\n",
    "\n",
    "            # Flip dimensions to have height as longest dimension\n",
    "            s = time.time()\n",
    "            if pic_hr.shape[2] > pic_hr.shape[1]:\n",
    "                pic_hr = pic_hr.transpose(1, 2)\n",
    "            if self.verbose: print(f'HR Flipping time: {time.time() - s:0.2f}')\n",
    "\n",
    "            # Normalization\n",
    "            s = time.time()\n",
    "            if self.normalize:\n",
    "                pic_hr_mean = torch.mean(pic_hr.flatten(start_dim=1), dim=1)\n",
    "                pic_hr_std = torch.std(pic_hr.flatten(start_dim=1), dim=1)\n",
    "                pic_hr = TF.normalize(pic_hr, mean=pic_hr_mean, std=pic_hr_std)\n",
    "            if self.verbose: print(f'HR Normalization time: {time.time() - s:0.2f}')\n",
    "\n",
    "            # Data augmentation for x and target\n",
    "            if self.data_augmentation != None:\n",
    "                pic_lr, pic_hr = self.data_augmentation_transform(pic_lr, pic_hr)\n",
    "          \n",
    "            # Final resize\n",
    "            s = time.time()\n",
    "            pic_lr = self.final_size_transf(pic_lr)\n",
    "            pic_hr = self.final_size_transf(pic_hr)\n",
    "            if self.verbose: print(f'Final resize time: {time.time() - s:0.2f}')\n",
    "\n",
    "            return pic_lr, pic_hr\n",
    "        \n",
    "        else:\n",
    "            # Final resize\n",
    "            s = time.time()\n",
    "            pic_lr = self.final_size_transf(pic_lr)\n",
    "            if self.verbose: print(f'Final resize time: {time.time() - s:0.2f}')\n",
    "\n",
    "            pic_lr_size = {'heights': pic_lr_h, 'widths': pic_lr_w}\n",
    "            pic_lr_norm_params = {'means': pic_lr_mean, 'stds': pic_lr_std}\n",
    "\n",
    "            return pic_lr, pic_lr_size, pic_lr_norm_params\n",
    "        \n",
    "\n",
    "    def data_augmentation_transform(self, pic_lr, pic_hr):       \n",
    "\n",
    "        assert pic_lr.shape == pic_hr.shape\n",
    "\n",
    "        pic_h, pic_w = pic_lr.shape[1], pic_lr.shape[2]\n",
    "\n",
    "        # Random rotation\n",
    "        s = time.time()\n",
    "        if 'rotate' in self.data_augmentation:\n",
    "            angle = transforms.RandomRotation.get_params(degrees=[-45,45])\n",
    "\n",
    "            pic_lr = TF.rotate(pic_lr, angle=angle)\n",
    "            pic_hr = TF.rotate(pic_hr, angle=angle)\n",
    "        if self.verbose: print(f'DA Rotation time: {time.time() - s:0.2f}')\n",
    "\n",
    "        # Random flip\n",
    "        s = time.time()\n",
    "        if 'flip' in self.data_augmentation:\n",
    "\n",
    "            # Random horizontal flipping\n",
    "            if np.random.random() > 0.5:\n",
    "                pic_lr = TF.hflip(pic_lr)\n",
    "                pic_hr = TF.hflip(pic_hr)\n",
    "\n",
    "            # Random vertical flipping\n",
    "            if np.random.random() > 0.5:\n",
    "                pic_lr = TF.vflip(pic_lr)\n",
    "                pic_hr = TF.vflip(pic_hr)\n",
    "        if self.verbose: print(f'DA Random Flipping time: {time.time() - s:0.2f}')\n",
    "\n",
    "        # Random crop\n",
    "        s = time.time()\n",
    "        if 'crop' in self.data_augmentation:\n",
    "            crop_factor = np.random.uniform(low=0.5, high=0.75)\n",
    "            crop_h = np.round(crop_factor * pic_h, decimals=0).astype(int)\n",
    "            crop_w = np.round(crop_factor * pic_w, decimals=0).astype(int)\n",
    "\n",
    "            i, j, h, w = transforms.RandomCrop.get_params(pic_lr, \n",
    "                                                          output_size=(crop_h, crop_w))\n",
    "            \n",
    "            pic_lr = TF.crop(img=pic_lr, top=i, left=j, height=h, width=w)\n",
    "            pic_hr = TF.crop(img=pic_hr, top=i, left=j, height=h, width=w)\n",
    "        if self.verbose: print(f'DA Cropping time: {time.time() - s:0.2f}')\n",
    "\n",
    "        # Resize to original shape\n",
    "        s = time.time()\n",
    "        original_size = transforms.Resize(size=[pic_h, pic_w], \n",
    "                                          interpolation=self.interpolation)\n",
    "        pic_lr = original_size(pic_lr)\n",
    "        pic_hr = original_size(pic_hr)\n",
    "        if self.verbose: print(f'DA Resizing time: {time.time() - s:0.2f}')\n",
    "\n",
    "        return pic_lr, pic_hr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TY3ljlLaQu9N"
   },
   "source": [
    "## Dataset visual check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 1070,
     "status": "ok",
     "timestamp": 1619653382034,
     "user": {
      "displayName": "Alejandro Alvarez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiJwO-DJto5fe7l3jpfrxCyKXIyVCJ_fxyVkAhw5g=s64",
      "userId": "03843718286559301780"
     },
     "user_tz": 240
    },
    "id": "EbgWqb5FQu9R"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def plot_pictures(dataset, idx='random'):\n",
    "\n",
    "    if idx == 'random': idx = np.random.randint(0, dataset.__len__() + 1)\n",
    "\n",
    "    if dataset.mode != 'test':\n",
    "\n",
    "        start = time.time()\n",
    "        pic_lr, pic_hr = dataset.__getitem__(idx)\n",
    "        if dataset.verbose: print(f'Total time: {time.time() - start:0.2f}\\n')\n",
    "\n",
    "        psnr = PSNR(data_range=1.0)\n",
    "        psnr.update((pic_lr.unsqueeze(0), pic_hr.unsqueeze(0)))\n",
    "        psnr_acc = psnr.compute()\n",
    "        psnr.reset()\n",
    "\n",
    "        ssim = SSIM(data_range=1.0)\n",
    "        ssim.update((pic_lr.unsqueeze(0), pic_hr.unsqueeze(0)))\n",
    "        ssim_acc = ssim.compute()\n",
    "        ssim.reset()\n",
    "\n",
    "        shape_lr = pic_lr.shape\n",
    "        shape_hr = pic_hr.shape\n",
    "        pic_lr = np.clip(pic_lr.permute(1,2,0).cpu().detach().numpy(), 0, 1)\n",
    "        pic_hr = np.clip(pic_hr.permute(1,2,0).cpu().detach().numpy(), 0, 1)\n",
    "        file_lr = dataset.file_names_lr[idx]\n",
    "        file_hr = dataset.file_names_hr[idx]\n",
    "\n",
    "        fig, axs = plt.subplots(1,2, figsize=(15,15))\n",
    "        axs[0].imshow(pic_lr)\n",
    "        title =  f'Low Resolution Image\\nSet: {dataset.mode}\\nNormalized: {dataset.normalize}\\n'\n",
    "        title += f'(shape: {shape_lr})\\nPSNR: {psnr_acc:0.2f}\\nSSIM: {ssim_acc:0.2f}\\n{file_lr}'\n",
    "        axs[0].set_title(title)\n",
    "        axs[1].imshow(pic_hr)\n",
    "        title =  f'High Resolution Image\\nSet: {dataset.mode}\\nNormalized: {dataset.normalize}\\n'\n",
    "        title += f'(shape: {shape_hr})\\nPSNR: {psnr_acc:0.2f}\\nSSIM: {ssim_acc:0.2f}\\n{file_hr}'\n",
    "        axs[1].set_title(title)\n",
    "        plt.show()\n",
    "\n",
    "    else: \n",
    "\n",
    "        start = time.time()\n",
    "        pic_lr, pic_lr_size, pic_lr_norm_params = dataset.__getitem__(idx)\n",
    "        if dataset.verbose: print(f'Total time: {time.time() - start:0.2f}\\n')\n",
    "\n",
    "        shape_lr = pic_lr.shape\n",
    "        file_lr = dataset.file_names_lr[idx]\n",
    "\n",
    "        pic_lr_unnormalized = pic_lr * pic_lr_norm_params['stds'].unsqueeze(1).unsqueeze(2) + \\\n",
    "                              pic_lr_norm_params['means'].unsqueeze(1).unsqueeze(1)\n",
    "        shape_lr_unnormalized = pic_lr_unnormalized.shape\n",
    "\n",
    "        resize_pic = transforms.Resize(size=[pic_lr_size['heights'], pic_lr_size['widths']],\n",
    "                                       interpolation=TF.InterpolationMode.BICUBIC)\n",
    "        pic_lr_resized = resize_pic(pic_lr)\n",
    "        shape_lr_resized = pic_lr_resized.shape\n",
    "\n",
    "        pic_lr_resized_unnormalized = resize_pic(pic_lr_unnormalized)\n",
    "        shape_lr_resized_unnormalized = pic_lr_resized_unnormalized.shape\n",
    "\n",
    "        pic_lr = np.clip(pic_lr.permute(1,2,0).cpu().detach().numpy(), 0, 1)\n",
    "        pic_lr_unnormalized = np.clip(pic_lr_unnormalized.permute(1,2,0).cpu().detach().numpy(), 0, 1)\n",
    "        pic_lr_resized = np.clip(pic_lr_resized.permute(1,2,0).cpu().detach().numpy(), 0, 1)\n",
    "        pic_lr_resized_unnormalized = np.clip(pic_lr_resized_unnormalized.permute(1,2,0).cpu().detach().numpy(), 0, 1)\n",
    "\n",
    "        fig, axs = plt.subplots(2,2, figsize=(15,23))\n",
    "\n",
    "        axs[0,0].imshow(pic_lr)\n",
    "        axs[0,0].set_title(f'Low Resolution Image\\nSet: {dataset.mode}\\nNormalized: {True}\\n(shape: {shape_lr})\\n{file_lr}')\n",
    "\n",
    "        axs[0,1].imshow(pic_lr_unnormalized)\n",
    "        axs[0,1].set_title(f'Low Resolution Image\\nSet: {dataset.mode}\\nNormalized: {False}\\n(shape: {shape_lr_unnormalized})\\n{file_lr}')\n",
    "\n",
    "        axs[1,0].imshow(pic_lr_resized)\n",
    "        axs[1,0].set_title(f'Low Resolution Image\\nOriginal size\\nSet: {dataset.mode}\\nNormalized: {True}\\n(shape: {shape_lr_resized})\\n{file_lr}')\n",
    "\n",
    "        axs[1,1].imshow(pic_lr_resized_unnormalized)\n",
    "        axs[1,1].set_title(f'Low Resolution Image\\nOriginal size\\nSet: {dataset.mode}\\nNormalized: {False}\\n(shape: {shape_lr_resized_unnormalized})\\n{file_lr}')\n",
    "\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 854
    },
    "executionInfo": {
     "elapsed": 25162,
     "status": "ok",
     "timestamp": 1619653282657,
     "user": {
      "displayName": "Alejandro Alvarez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiJwO-DJto5fe7l3jpfrxCyKXIyVCJ_fxyVkAhw5g=s64",
      "userId": "03843718286559301780"
     },
     "user_tz": 240
    },
    "id": "_PkOz-VVQu9T",
    "outputId": "4d8a1ab6-9d3f-4e5d-9634-140bbdb42db3"
   },
   "outputs": [],
   "source": [
    "# mode = 'test'\n",
    "# FINAL_SIZE = 2040\n",
    "# normalize=True\n",
    "# data_augmentation = ['crop', 'rotate', 'flip'] if mode == 'train' else None\n",
    "# interpolation = TF.InterpolationMode.BILINEAR\n",
    "# in_memory=False\n",
    "# verbose=False\n",
    "\n",
    "# dataset = PicturesDataset(mode=mode, \n",
    "#                           final_size=FINAL_SIZE,\n",
    "#                           normalize=normalize, \n",
    "#                           data_augmentation=data_augmentation, \n",
    "#                           interpolation=interpolation,\n",
    "#                           in_memory=in_memory,\n",
    "#                           verbose=verbose)\n",
    "\n",
    "# # plot_pictures(dataset=dataset, idx=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_loader = DataLoader(dataset,\n",
    "#                              shuffle=False, \n",
    "#                              batch_size=2,\n",
    "#                              num_workers=0, \n",
    "#                              pin_memory=False,\n",
    "#                              drop_last=False)\n",
    "# imgs = iter(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# pic_lr, pic_lr_size, pic_lr_norm_params = next(imgs)\n",
    "# # print(pic_lr.shape)\n",
    "# # print(len(pic_lr_rs))\n",
    "# # print(pic_lr_size['heights'])\n",
    "# # print(pic_lr_size['widths'])\n",
    "# # print(pic_lr_norm_params['means'].unsqueeze(2).unsqueeze(3).shape)\n",
    "# # print(pic_lr_norm_params['stds'].unsqueeze(2).unsqueeze(3).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pic_lr_rs = pic_lr * pic_lr_norm_params['stds'].unsqueeze(2).unsqueeze(3) + pic_lr_norm_params['means'].unsqueeze(2).unsqueeze(3)\n",
    "# pic_lr_rs = [TF.resize(pic_lr_rs[i], \n",
    "#                                     size=[pic_lr_size['heights'][i].item(), \n",
    "#                                           pic_lr_size['widths'][i].item()],\n",
    "#                                     interpolation=TF.InterpolationMode.BICUBIC) \\\n",
    "#                           for i in range(len(pic_lr_rs))]\n",
    "\n",
    "# pic1_or = transforms.ToTensor()(Image.open(dataset.file_names_lr[8]))\n",
    "# pic2_or = transforms.ToTensor()(Image.open(dataset.file_names_lr[9]))\n",
    "\n",
    "# ssim = SSIM(data_range=1.0)\n",
    "\n",
    "# fig, axs = plt.subplots(2,3, figsize=(15,15))\n",
    "# axs[0,0].imshow(pic_lr[0,:,:,:].permute(1,2,0))\n",
    "# axs[0,1].imshow(pic_lr_rs[0].permute(1,2,0))\n",
    "# axs[0,2].imshow(pic1_or.permute(1,2,0))\n",
    "# ssim.update((pic_lr_rs[0].unsqueeze(0), pic1_or.unsqueeze(0)))\n",
    "# ssim_acc = ssim.compute()\n",
    "# ssim.reset()\n",
    "# axs[0,2].set_title(f'SSIM: {ssim_acc}')\n",
    "# axs[1,0].imshow(pic_lr[1,:,:,:].permute(1,2,0))\n",
    "# axs[1,1].imshow(pic_lr_rs[1].permute(1,2,0))\n",
    "# axs[1,2].imshow(pic2_or.permute(1,2,0))\n",
    "# ssim.update((pic_lr_rs[1].unsqueeze(0), pic2_or.unsqueeze(0)))\n",
    "# ssim_acc = ssim.compute()\n",
    "# ssim.reset()\n",
    "# axs[1,2].set_title(f'SSIM: {ssim_acc}')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L7tLqjSUQu9V"
   },
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 1398,
     "status": "ok",
     "timestamp": 1619651176460,
     "user": {
      "displayName": "Alejandro Alvarez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiJwO-DJto5fe7l3jpfrxCyKXIyVCJ_fxyVkAhw5g=s64",
      "userId": "03843718286559301780"
     },
     "user_tz": 240
    },
    "id": "3JcqCjMTQu9s"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def create_dataloaders(mc):\n",
    "    \n",
    "    NUM_WORKERS = os.cpu_count()\n",
    "\n",
    "    train_dataset = PicturesDataset(mode='train', \n",
    "                                    final_size=mc['final_size'],\n",
    "                                    normalize=mc['normalize'], \n",
    "                                    data_augmentation=mc['data_augmentation'], \n",
    "                                    interpolation=mc['interpolation'],\n",
    "                                    in_memory=mc['in_memory'],\n",
    "                                    verbose=False)\n",
    "    \n",
    "    val_dataset =   PicturesDataset(mode='val', \n",
    "                                    final_size=mc['final_size'],\n",
    "                                    normalize=mc['normalize'], \n",
    "                                    data_augmentation=None, \n",
    "                                    interpolation=mc['interpolation'],\n",
    "                                    in_memory=mc['in_memory'],\n",
    "                                    verbose=False)\n",
    "    \n",
    "    test_dataset =  PicturesDataset(mode='test', \n",
    "                                    final_size=mc['final_size'],\n",
    "                                    normalize=mc['normalize'], \n",
    "                                    data_augmentation=None, \n",
    "                                    interpolation=mc['interpolation'],\n",
    "                                    in_memory=False,\n",
    "                                    verbose=False)\n",
    "    \n",
    "    display_str  = f'n_train: {len(train_dataset)} '\n",
    "    display_str += f'n_val: {len(val_dataset)} '\n",
    "    display_str += f'n_test: {len(test_dataset)} '\n",
    "    print(display_str)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, \n",
    "                              shuffle=True, \n",
    "                              batch_size=mc['batch_size'], \n",
    "                              num_workers=NUM_WORKERS, \n",
    "                              pin_memory=torch.cuda.is_available(),\n",
    "                              drop_last=True)\n",
    "    \n",
    "    val_loader = DataLoader(val_dataset,\n",
    "                            shuffle=False, \n",
    "                            batch_size=mc['batch_size'],\n",
    "                            num_workers=NUM_WORKERS, \n",
    "                            pin_memory=torch.cuda.is_available(),\n",
    "                            drop_last=True)\n",
    "    \n",
    "    test_loader = DataLoader(test_dataset,\n",
    "                             shuffle=False, \n",
    "                             batch_size=mc['batch_size'],\n",
    "                             num_workers=NUM_WORKERS, \n",
    "                             pin_memory=torch.cuda.is_available(),\n",
    "                             drop_last=False)\n",
    "    \n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "SihcEvikQu9s",
    "outputId": "d6aed160-6828-4695-c410-dc7fb68b1427"
   },
   "outputs": [],
   "source": [
    "# FINAL_SIZE = 2040\n",
    "# NUM_WORKERS = os.cpu_count()\n",
    "\n",
    "# mc = {'h_channels': [8, 16, 32],\n",
    "#       'final_size': FINAL_SIZE,\n",
    "#       'normalize': True,\n",
    "#       'data_augmentation': ['crop', 'rotate', 'flip'],\n",
    "#       'interpolation': TF.InterpolationMode.BILINEAR,\n",
    "#       'in_memory': False,\n",
    "#       'batch_size': 64}\n",
    "\n",
    "# train_loader, val_loader, test_loader = create_dataloaders(mc)\n",
    "\n",
    "# print('\\nTrain loader:')\n",
    "# s = time.time()\n",
    "# batch_lr, batch_hr = next(iter(train_loader))\n",
    "# print(time.time() - s)\n",
    "# print(f'batch_lr.shape: {batch_lr.shape}')\n",
    "# print(f'batch_hr.shape: {batch_hr.shape}')\n",
    "\n",
    "# print('\\nVal loader:')\n",
    "# s = time.time()\n",
    "# batch_lr, batch_hr = next(iter(val_loader))\n",
    "# print(time.time() - s)\n",
    "# print(f'batch_lr.shape: {batch_lr.shape}')\n",
    "# print(f'batch_hr.shape: {batch_hr.shape}')\n",
    "\n",
    "# print('\\nTest loader:')\n",
    "# s = time.time()\n",
    "# batch_lr, batch_lr_size, batch_lr_norm_params = next(iter(test_loader))\n",
    "# print(time.time() - s)\n",
    "# print(f'batch_lr.shape: {batch_lr.shape}')\n",
    "# print(f'batch_hr_sizes:\\n{batch_lr_size}')\n",
    "# print(f'batch_lr_norm_params:\\n{batch_lr_norm_params}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UxLwRNCMQu9t"
   },
   "source": [
    "## Autoencoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 325,
     "status": "ok",
     "timestamp": 1619651850810,
     "user": {
      "displayName": "Alejandro Alvarez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiJwO-DJto5fe7l3jpfrxCyKXIyVCJ_fxyVkAhw5g=s64",
      "userId": "03843718286559301780"
     },
     "user_tz": 240
    },
    "id": "5U7-SpYaQu9t"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "class _autoencoder(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 h_channels):\n",
    "\n",
    "        super(_autoencoder, self).__init__()\n",
    "        \n",
    "        h_channels = list(h_channels)\n",
    "        self.channels_enc = [3]\n",
    "        self.channels_enc += h_channels.copy()\n",
    "        self.channels_dec = [self.channels_enc[-1]]\n",
    "        self.channels_dec += h_channels[::-1].copy()\n",
    "\n",
    "        # Input layer: (B, C=3, H, W)\n",
    "\n",
    "        # Encoder\n",
    "        encoder_layers = []\n",
    "\n",
    "        for i in range(len(h_channels)):\n",
    "            layer = [nn.Conv2d(in_channels=self.channels_enc[i], \n",
    "                               out_channels=self.channels_enc[i+1], \n",
    "                               kernel_size=3,\n",
    "                               padding=1),\n",
    "                     nn.BatchNorm2d(num_features=self.channels_enc[i+1]),\n",
    "                     nn.ReLU(),\n",
    "                     nn.MaxPool2d(kernel_size=2,\n",
    "                                  stride=2)]\n",
    "            encoder_layers += layer\n",
    "\n",
    "        self.encoder_layers = nn.ModuleList(encoder_layers)\n",
    "\n",
    "        # Decoder\n",
    "        decoder_layers = []\n",
    "\n",
    "        for i in range(len(self.channels_dec) - 1):\n",
    "            layer = [nn.ConvTranspose2d(in_channels=self.channels_dec[i], \n",
    "                                        out_channels=self.channels_dec[i+1], \n",
    "                                        kernel_size=2,\n",
    "                                        stride=2),\n",
    "                     nn.BatchNorm2d(num_features=self.channels_dec[i+1]),\n",
    "                     nn.ReLU()]\n",
    "            decoder_layers += layer\n",
    "\n",
    "        decoder_layers += [nn.Conv2d(in_channels=self.channels_dec[i+1], \n",
    "                                    out_channels=self.channels_enc[0], \n",
    "                                    kernel_size=3,\n",
    "                                    padding=1),\n",
    "                           nn.BatchNorm2d(num_features=self.channels_enc[0]),\n",
    "                           nn.ReLU()]\n",
    "        \n",
    "        self.decoder_layers = nn.ModuleList(decoder_layers)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # Encoding (Convolutional Blocks - Downsampling)\n",
    "        output_shapes = []\n",
    "        res_x = []\n",
    "\n",
    "        for layer in self.encoder_layers:            \n",
    "            if isinstance(layer, torch.nn.modules.pooling.MaxPool2d):\n",
    "                output_shapes.append(x.shape)\n",
    "                \n",
    "            x = layer(x)\n",
    "            \n",
    "            if isinstance(layer, torch.nn.modules.Conv2d): # skip connections\n",
    "                res_x.append(x)\n",
    "\n",
    "        output_shapes = output_shapes[::-1]\n",
    "        res_x = res_x[::-1]\n",
    "\n",
    "        # Decoding (Transpose Convolutional Blocks - Upsampling)\n",
    "        for i, layer in enumerate(self.decoder_layers):\n",
    "            if isinstance(layer, torch.nn.modules.conv.ConvTranspose2d):\n",
    "                x = layer(x, output_size=output_shapes[i//3]) # if layer is ConvTranspose2D, then call it preserving output size from encoder\n",
    "                x += res_x[i//3] # skip connections\n",
    "            else:\n",
    "                x = layer(x)\n",
    "    \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "JufpDfWGQu9u",
    "outputId": "b157c349-b23f-4ec6-c994-4ad59e40a73e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─ModuleList: 1                          []                        --\n",
      "|    └─Conv2d: 2-1                       [8, 8, 205, 205]          224\n",
      "|    └─BatchNorm2d: 2-2                  [8, 8, 205, 205]          16\n",
      "|    └─ReLU: 2-3                         [8, 8, 205, 205]          --\n",
      "|    └─MaxPool2d: 2-4                    [8, 8, 102, 102]          --\n",
      "├─ModuleList: 1                          []                        --\n",
      "|    └─ConvTranspose2d: 2-5              [8, 8, 205, 205]          264\n",
      "|    └─BatchNorm2d: 2-6                  [8, 8, 205, 205]          16\n",
      "|    └─ReLU: 2-7                         [8, 8, 205, 205]          --\n",
      "|    └─Conv2d: 2-8                       [8, 3, 205, 205]          219\n",
      "|    └─BatchNorm2d: 2-9                  [8, 3, 205, 205]          6\n",
      "|    └─ReLU: 2-10                        [8, 3, 205, 205]          --\n",
      "==========================================================================================\n",
      "Total params: 745\n",
      "Trainable params: 745\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 231.31\n",
      "==========================================================================================\n",
      "Input size (MB): 4.03\n",
      "Forward/backward pass size (MB): 102.20\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 106.24\n",
      "==========================================================================================\n",
      "_autoencoder(\n",
      "  (encoder_layers): ModuleList(\n",
      "    (0): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (decoder_layers): ModuleList(\n",
      "    (0): ConvTranspose2d(8, 8, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Conv2d(8, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# mode = 'train'\n",
    "# FINAL_SIZE = 205\n",
    "# normalize=True\n",
    "# data_augmentation = ['crop', 'rotate', 'flip'] if mode == 'train' else None\n",
    "# interpolation = TF.InterpolationMode.BILINEAR\n",
    "# in_memory=False\n",
    "# verbose=False\n",
    "\n",
    "# dataset = PicturesDataset(mode=mode, \n",
    "#                           final_size=FINAL_SIZE,\n",
    "#                           normalize=normalize, \n",
    "#                           data_augmentation=data_augmentation, \n",
    "#                           interpolation=interpolation,\n",
    "#                           verbose=verbose)\n",
    "\n",
    "# idx = np.random.randint(0, dataset.__len__() + 1)\n",
    "\n",
    "# pic_lr, pic_hr = dataset.__getitem__(idx)\n",
    "# pic_lr = pic_lr.unsqueeze(0)\n",
    "\n",
    "# print(f'input  shape: {pic_lr.shape}')\n",
    "model = _autoencoder(h_channels=[8])\n",
    "# out_pic = model(pic_lr)\n",
    "# print(f'output shape: {out_pic.shape}')\n",
    "print(summary(model, input_size=(8, 3, 205, 205)))\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RFg9gTQbQu9v"
   },
   "source": [
    "## Autoencoder Model Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "executionInfo": {
     "elapsed": 1290,
     "status": "ok",
     "timestamp": 1619718954502,
     "user": {
      "displayName": "Alejandro Alvarez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiJwO-DJto5fe7l3jpfrxCyKXIyVCJ_fxyVkAhw5g=s64",
      "userId": "03843718286559301780"
     },
     "user_tz": 240
    },
    "id": "jqaQwKg6Qu9v"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "class autoencoder(object):\n",
    "\n",
    "    def __init__(self, params):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.params = params\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        # Instantiate model\n",
    "\n",
    "        #------------------------------------ Model & Optimizer ----------------------------------#    \n",
    "\n",
    "        self.model = _autoencoder(h_channels=params['h_channels'])\n",
    "        \n",
    "        print(summary(self.model, \n",
    "                      input_size=(params['batch_size'], \n",
    "                                  3, \n",
    "                                  params['final_size'], \n",
    "                                  params['final_size'])))\n",
    "\n",
    "        self.model = nn.DataParallel(self.model).to(self.device)\n",
    "\n",
    "        self.optimizer = AdamW(self.model.parameters(), \n",
    "                               lr=params['initial_lr'],\n",
    "                               weight_decay=params['weight_decay']) # Moved the optimizer outside\n",
    "                                                                    # the fit method to also save \n",
    "                                                                    # the optimizer state_dict.\n",
    "\n",
    "        self.psnr = PSNR(data_range=1.0)\n",
    "        self.ssim = SSIM(data_range=1.0)\n",
    "\n",
    "    def fit(self, train_loader, val_loader):\n",
    "        \n",
    "        params = self.params\n",
    "        \n",
    "        self.time_stamp = time.time()\n",
    "        \n",
    "        #------------------------------------- Optimization --------------------------------------#\n",
    "        if params['criterion'] == 'ssim':\n",
    "            cirterion = pytorch_ssim.SSIM()\n",
    "        else:\n",
    "            criterion = nn.MSELoss()\n",
    "        \n",
    "\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(self.optimizer, \n",
    "                                                    step_size=params['adjust_lr_step'], \n",
    "                                                    gamma=params['lr_decay'])\n",
    "                                                                            \n",
    "        scaler = torch.cuda.amp.GradScaler()\n",
    "        \n",
    "        #---------------------------------------- Logging -----------------------------------------#\n",
    "        step = 0\n",
    "        epoch = 0\n",
    "        break_flag = False\n",
    "        self.best_ssim = 0\n",
    "        \n",
    "        trajectories = {'step':  [], \n",
    "                        'epoch':  [],\n",
    "                        'train_loss': [], \n",
    "                        'val_loss': [],\n",
    "                        'train_psnr': [],\n",
    "                        'val_psnr': [],\n",
    "                        'train_ssim': [],\n",
    "                        'val_ssim': []}\n",
    "\n",
    "        print('\\n'+'='*43+' Fitting  Autoencoder Model '+'='*43)\n",
    "\n",
    "        while step <= params['iterations']:\n",
    "            # Train\n",
    "            epoch += 1\n",
    "                        \n",
    "            self.model.train()\n",
    "\n",
    "            start_epoch = time.time()\n",
    "\n",
    "            for batch_idx, (x_lr, target_hr) in enumerate(train_loader):\n",
    "\n",
    "                step+=1           \n",
    "                \n",
    "                if break_flag: # weird epoch breaker\n",
    "                    continue\n",
    "                \n",
    "                #--------------------------------- Forward and Backward ---------------------------------#\n",
    "                x_lr = x_lr.to(self.device) \n",
    "                target_hr = target_hr.to(self.device) \n",
    "                \n",
    "                self.optimizer.zero_grad()\n",
    "                \n",
    "                with torch.cuda.amp.autocast():\n",
    "\n",
    "                    outputs = self.model(x_lr.float()) \n",
    "\n",
    "                    \n",
    "                    if params['criterion'] == 'ssim':\n",
    "                        loss = -criterion(outputs, target_hr)\n",
    "                    else:\n",
    "                        loss = criterion(outputs, target_hr)\n",
    "\n",
    "                    scaler.scale(loss).backward()\n",
    "                    scaler.step(self.optimizer)\n",
    "                    # Update optimizer learning rate\n",
    "                    scaler.update()\n",
    "                 \n",
    "                del x_lr\n",
    "                del target_hr\n",
    "                del outputs\n",
    "                torch.cuda.empty_cache()\n",
    "                \n",
    "                scheduler.step()\n",
    "\n",
    "            time_epoch = time.time() - start_epoch\n",
    "\n",
    "                #----------------------------------- Evaluate metrics -----------------------------------#\n",
    "            if (step % params['display_step']) == 0:\n",
    "\n",
    "                start_eval = time.time()\n",
    "        \n",
    "                train_loss, train_psnr, train_ssim = \\\n",
    "                    self.evaluate_performance(train_loader, criterion)\n",
    "                val_loss, val_psnr, val_ssim = \\\n",
    "                    self.evaluate_performance(val_loader, criterion)\n",
    "\n",
    "                time_eval = time.time() - start_eval\n",
    "                                    \n",
    "                display_str = f'\\nepoch: {epoch} (step: {step}) * '\n",
    "                display_str += f'training time: {time_epoch:0.2f} '\n",
    "                display_str += f'evaluation time: {time_eval:0.2f} * '\n",
    "                display_str += f'train_loss: {train_loss:.4f} '\n",
    "                display_str += f'val_loss: {val_loss:.4f} * '\n",
    "                display_str += f'train_psnr: {train_psnr:0.2f} train_ssim: {train_ssim:0.2f} '\n",
    "                display_str += f'val_psnr: {val_psnr:0.2f} val_ssim: {val_ssim:0.2f}'\n",
    "                                \n",
    "                print(display_str)\n",
    "                \n",
    "                trajectories['train_loss'] += [train_loss]\n",
    "                trajectories['val_loss']   += [val_loss]\n",
    "                trajectories['train_psnr'] += [train_psnr]\n",
    "                trajectories['val_psnr']   += [val_psnr]\n",
    "                trajectories['train_ssim'] += [train_ssim]\n",
    "                trajectories['val_ssim']   += [val_ssim]\n",
    "                \n",
    "                if val_ssim > self.best_ssim:\n",
    "                    \n",
    "                    path = f\"./checkpoint/{args.experiment_id}_{self.time_stamp}_ckpt.pth\"\n",
    "                    print(f'Saving to {path}')\n",
    "                    self.best_ssim = val_ssim\n",
    "                    self.save_weights(path=path,\n",
    "                                      epoch=epoch,\n",
    "                                      train_loss=train_loss,\n",
    "                                      val_loss=val_loss,\n",
    "                                      train_psnr=train_psnr,\n",
    "                                      val_psnr=val_psnr,\n",
    "                                      train_ssim=train_ssim,\n",
    "                                      val_ssim=val_ssim)\n",
    "                    \n",
    "            if step > params['iterations']:\n",
    "                break_flag=True\n",
    "\n",
    "        #---------------------------------------- Final Logs -----------------------------------------#\n",
    "        print('\\n'+'='*43+' Finished Train '+'='*43)\n",
    "        self.train_loss = trajectories['train_loss'][-1]\n",
    "        self.val_loss = trajectories['val_loss'][-1]\n",
    "        self.train_psnr = trajectories['train_psnr'][-1]\n",
    "        self.val_psnr = trajectories['val_psnr'][-1]\n",
    "        self.train_ssim = trajectories['train_ssim'][-1]\n",
    "        self.val_ssim = trajectories['val_ssim'][-1]\n",
    "        self.trajectories = trajectories\n",
    "        \n",
    "        \n",
    "    def evaluate_performance(self, loader, criterion):\n",
    "        \n",
    "        self.model.eval()\n",
    "        params = self.params\n",
    "        running_loss = 0\n",
    "           \n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (x_lr, target_hr) in enumerate(loader):\n",
    "                     \n",
    "                x_lr = x_lr.to(self.device) \n",
    "                target_hr = target_hr.to(self.device) \n",
    "\n",
    "                outputs = self.model(x_lr.float()) \n",
    "                loss = criterion(outputs, target_hr)\n",
    "\n",
    "                running_loss += loss.item()  \n",
    "                self.psnr.update((outputs, target_hr))\n",
    "                self.ssim.update((outputs, target_hr))\n",
    "                          \n",
    "                # Clean memory\n",
    "                del x_lr\n",
    "                del target_hr\n",
    "                del outputs\n",
    "                torch.cuda.empty_cache()  \n",
    "\n",
    "        running_loss /= len(loader) * params['batch_size']\n",
    "        psnr_score = self.psnr.compute()\n",
    "        ssim_score = self.ssim.compute()\n",
    "\n",
    "        self.psnr.reset()\n",
    "        self.ssim.reset() \n",
    "        \n",
    "        self.model.train()\n",
    "\n",
    "        return running_loss, psnr_score, ssim_score\n",
    "    \n",
    "    def predict_labels(self, loader):\n",
    "\n",
    "        self.model.eval()\n",
    "        outputs_hr = [] \n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (x_lr, x_lr_size, x_lr_norm_params) in tqdm(enumerate(loader)):    \n",
    "                     \n",
    "                x_lr = x_lr.to(self.device) \n",
    "                x_lr_size['heights'] = x_lr_size['heights'].to(self.device)\n",
    "                x_lr_size['widths'] = x_lr_size['widths'].to(self.device)\n",
    "\n",
    "                x_lr_norm_params['stds'] = x_lr_norm_params['stds'].to(self.device)\n",
    "                x_lr_norm_params['means'] = x_lr_norm_params['means'].to(self.device) \n",
    "\n",
    "                outputs = self.model(x_lr.float()) \n",
    "\n",
    "                outputs = x_lr * x_lr_norm_params['stds'].unsqueeze(2).unsqueeze(3) + \\\n",
    "                          x_lr_norm_params['means'].unsqueeze(2).unsqueeze(3)\n",
    "                \n",
    "                outputs_hr += [TF.resize(outputs[i], \n",
    "                                         size=[x_lr_size['heights'][i].item(), \n",
    "                                               x_lr_size['widths'][i].item()],\n",
    "                                         interpolation=TF.InterpolationMode.BICUBIC) \\\n",
    "                               for i in range(len(outputs))]\n",
    "                \n",
    "                # Clean memory\n",
    "                del x_lr\n",
    "                del x_lr_size\n",
    "                del x_lr_norm_params\n",
    "                del outputs\n",
    "                torch.cuda.empty_cache()\n",
    "        \n",
    "        return outputs_hr\n",
    "    \n",
    "    def save_weights(self, \n",
    "                     path, \n",
    "                     epoch, \n",
    "                     train_loss, \n",
    "                     val_loss, \n",
    "                     train_psnr, \n",
    "                     val_psnr, \n",
    "                     train_ssim, \n",
    "                     val_ssim):\n",
    "\n",
    "        if not os.path.exists('./checkpoint/'):\n",
    "            os.makedirs('./checkpoint/')\n",
    "\n",
    "        torch.save({'epoch': epoch,\n",
    "                    'model_state_dict': self.model.state_dict(),\n",
    "                    'optimizer_state_dict': self.optimizer.state_dict(), \n",
    "                    'train_loss': train_loss,\n",
    "                    'val_loss': val_loss,\n",
    "                    'train_psnr': train_psnr,\n",
    "                    'val_psnr': val_psnr,\n",
    "                    'train_ssim': train_ssim,\n",
    "                    'val_ssim': val_ssim},\n",
    "                    path)  \n",
    "\n",
    "    def load_weights(self, path):\n",
    "\n",
    "        checkpoint = torch.load(path, map_location=torch.device(self.device))\n",
    "\n",
    "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        self.model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1123,
     "status": "ok",
     "timestamp": 1619658680379,
     "user": {
      "displayName": "Alejandro Alvarez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiJwO-DJto5fe7l3jpfrxCyKXIyVCJ_fxyVkAhw5g=s64",
      "userId": "03843718286559301780"
     },
     "user_tz": 240
    },
    "id": "FvPyx5x7Qu9y",
    "outputId": "82a47bd7-03fe-4676-d912-929852ca9b05"
   },
   "outputs": [],
   "source": [
    "# FINAL_SIZE = 205\n",
    "# NUM_WORKERS = os.cpu_count()\n",
    "# DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# model_path = f\"./checkpoint/debugging_ckpt.pth\"\n",
    "# trials_path = f\"./results/debugging_trials.p\"\n",
    "\n",
    "# iterations = 1_000\n",
    "# n_epochs = 10\n",
    "# display_step = 100\n",
    "\n",
    "# mc = {'experiment_id': 'debugging',\n",
    "#       'h_channels': [8],\n",
    "#       'final_size': FINAL_SIZE,\n",
    "#       'normalize': True,\n",
    "# #       'data_augmentation': ['crop', 'rotate', 'flip'],\n",
    "#       'data_augmentation': None,\n",
    "#       'interpolation': TF.InterpolationMode.NEAREST,\n",
    "#       'in_memory': False,\n",
    "#       'criterion': 'mse',\n",
    "#       'batch_size': 8,\n",
    "#       'initial_lr': 1e-2,\n",
    "#       'weight_decay': 1e-6,\n",
    "#       'adjust_lr_step': 3_000,\n",
    "#       'lr_decay': 0.1,\n",
    "#       'iterations': iterations,\n",
    "#       'n_epochs': n_epochs,\n",
    "#       'display_step': display_step,\n",
    "#       'path': model_path,\n",
    "#       'trials_path': trials_path,\n",
    "#       'random_seed': 7}\n",
    "\n",
    "# train_loader, val_loader, test_loader = create_dataloaders(mc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1762,
     "status": "ok",
     "timestamp": 1619658683254,
     "user": {
      "displayName": "Alejandro Alvarez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiJwO-DJto5fe7l3jpfrxCyKXIyVCJ_fxyVkAhw5g=s64",
      "userId": "03843718286559301780"
     },
     "user_tz": 240
    },
    "id": "_2O8BB0tQu90",
    "outputId": "1fd0a154-b9bc-473a-9fc9-08c0d8282504"
   },
   "outputs": [],
   "source": [
    "# model = autoencoder(params=mc)\n",
    "# gc.collect()\n",
    "# model.fit(train_loader=train_loader, val_loader=val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "LJoKi1A-u39p"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def fit_and_log(mc, verbose, trials=None):\n",
    "\n",
    "    start_time = time.time()    \n",
    "    \n",
    "    train_loader, val_loader, _ = create_dataloaders(mc)\n",
    "\n",
    "    print('='*50)\n",
    "    print(pd.Series(mc))\n",
    "    print('='*50+'\\n')\n",
    "        \n",
    "    model = autoencoder(params=mc)\n",
    "        \n",
    "    model.fit(train_loader=train_loader, \n",
    "              val_loader=val_loader)\n",
    "    \n",
    "    results = {#----------------- Hyperopt -----------------#\n",
    "               'loss': model.val_loss,\n",
    "               'status': STATUS_OK,\n",
    "               'mc': mc,\n",
    "               'path': mc['path'],\n",
    "               #------------------- Logs -------------------#\n",
    "               'train_loss': model.train_loss,\n",
    "               'val_loss': model.val_loss,\n",
    "               'train_psnr': model.train_psnr,\n",
    "               'val_psnr': model.val_psnr,\n",
    "               'train_ssim': model.train_ssim,\n",
    "               'val_ssim': model.val_ssim,\n",
    "               'run_time': time.time()-start_time,\n",
    "               'trajectories': model.trajectories} \n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from hyperopt import Trials, fmin, hp, tpe\n",
    "from hyperopt.pyll.base import scope\n",
    "from functools import partial\n",
    "import argparse\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from hyperopt import STATUS_OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def parse_args():\n",
    "    desc = \"Autoencoder for image super-resolution\"\n",
    "    parser = argparse.ArgumentParser(description=desc)\n",
    "    parser.add_argument('--n_epochs', required=True, type=int, help='number of epochs')\n",
    "    parser.add_argument('--batch_size', required=True, type=int, help='Batch size')\n",
    "    parser.add_argument('--n_eval_steps', required=True, type=int, help='Number of display and eval steps')\n",
    "    parser.add_argument('--hyperopt_max_evals', required=True, type=int, help='Hyperopt evaluations')\n",
    "    parser.add_argument('--experiment_id', required=True, type=str, help='string to identify experiment')\n",
    "    return parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def main(args, max_evals):\n",
    "    \n",
    "    model_path = f\"./checkpoint/{args.experiment_id}_ckpt.pth\"\n",
    "    trials_path = f\"./results/{args.experiment_id}_trials.p\"\n",
    "    \n",
    "    iterations = (800 // args.batch_size) * args.n_epochs\n",
    "    \n",
    "    display_step = iterations // args.n_eval_steps\n",
    "    \n",
    "    space = {'experiment_id': hp.choice(label='experiment_id', options=[args.experiment_id]),\n",
    "             #------------------------------------- Architecture -------------------------------------# \n",
    "#              'h_channels': hp.choice(label='h_channels', options=[[8, 16, 32, 64, 128, 256]]),\n",
    "             'h_channels': hp.choice(label='h_channels', options=[[8, 16, 32, 64, 128, 256]]),\n",
    "             'final_size': hp.choice(label='final_size', options=[2040]),\n",
    "             'normalize': hp.choice(label='normalize', options=[True]),\n",
    "             'data_augmentation': hp.choice(label='data_augmentation', options=[['crop', 'rotate', 'flip']]),\n",
    "             'interpolation': hp.choice(label='interpolation', options=[TF.InterpolationMode.BILINEAR]),\n",
    "             'in_memory': hp.choice(label='in_memory', options=[False]),\n",
    "             'criterion': hp.choice(label='criterion', options=['mse']),\n",
    "             #------------------------------ Optimization Regularization -----------------------------#\n",
    "             'batch_size': hp.choice(label='batch_size', options=[args.batch_size]),\n",
    "             'initial_lr': hp.loguniform(label='initial_lr', low=np.log(5e-3), high=np.log(1e-2)),\n",
    "             'weight_decay': scope.float(hp.choice(label='weight_decay', options=[1e-6])),\n",
    "             'adjust_lr_step': hp.choice(label='adjust_lr_step', options=[iterations//3]),\n",
    "             'lr_decay': scope.float(hp.choice(label='lr_decay', options=[0.1])),\n",
    "             'iterations': hp.choice(label='iterations', options=[iterations]),\n",
    "             'n_epochs': hp.choice(label='n_epochs', options=[args.n_epochs]),\n",
    "             'display_step': hp.choice(label='display_step', options=[display_step]),\n",
    "             #--------------------------------------   Others   --------------------------------------#\n",
    "             'path': hp.choice(label='path', options=[model_path]),\n",
    "             'trials_path': hp.choice(label='trials_path', options=[trials_path]),\n",
    "             'random_seed': hp.choice(label='random_seed', options=[[2, 3, 5, 7, 11]])}\n",
    "\n",
    "\n",
    "    trials = Trials()\n",
    "    fmin_objective = partial(fit_and_log, trials=trials, verbose=True)\n",
    "    best_model = fmin(fmin_objective, space=space, algo=tpe.suggest, max_evals=max_evals, trials=trials)\n",
    "    \n",
    "    with open(trials_path, \"wb\") as f:\n",
    "        pickle.dump(trials, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "if __name__ == \"__main__\":\n",
    "    gc.collect()\n",
    "    gc.get_count()\n",
    "    args = parse_args()\n",
    "\n",
    "#     args = pd.Series({'n_epochs': 10, \n",
    "#                       'batch_size': 8, \n",
    "#                       'hyperopt_max_evals': 1,\n",
    "#                       'experiment_id': 'debugging'})\n",
    "    main(args, max_evals=args.hyperopt_max_evals)\n",
    "    \n",
    "# PYTHONPATH=. python super_resolution/autoencoder.py --n_epochs 100 --batch_size 8  --n_eval_steps 5 --hyperopt_max_evals 3 --experiment_id \"debugging\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "autoencoder.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Environment (conda_idl_ubuntu)",
   "language": "python",
   "name": "conda_idl_ubuntu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
